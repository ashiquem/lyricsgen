{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Lyrics from Genius "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = open('token.txt','r').readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_song_info(artist,title,token):\n",
    "    \n",
    "    genius_api_url = 'https://api.genius.com'\n",
    "    headers = {'Authorization': 'Bearer ' + token}\n",
    "    \n",
    "    def requires_formatting(strng):\n",
    "        requires = False\n",
    "        if any(x in strng for x in string.punctuation) | (strng.find('Feat') > -1):\n",
    "            requires = True            \n",
    "        return requires\n",
    "    \n",
    "    def format_string(strng):\n",
    "        #remove featuring artists\n",
    "        strng = strng.split('Feat')[0].strip()\n",
    "        #remove special characters\n",
    "        translator = str.maketrans('','',string.punctuation)\n",
    "        formatted = strng.translate(translator)\n",
    "        formatted = formatted.lower().strip()\n",
    "\n",
    "        return formatted\n",
    "    \n",
    "    def search_path(artist,title,search_hits,format_=False):\n",
    "        song_path = ''\n",
    "        \n",
    "        for hit in search_hits:\n",
    "            a = hit['result']['primary_artist']['name']\n",
    "            if format_:\n",
    "                a = format_string(artist)\n",
    "            t = hit['result']['title'] \n",
    "            \n",
    "            if  (a in artist) and (title.lower() in t.lower()):\n",
    "                song_path = hit['result']['path']\n",
    "                break\n",
    "        \n",
    "        return song_path\n",
    "    \n",
    "    def get_path(artist,title,headers,format_=False):\n",
    "        search_url = genius_api_url + '/search'  \n",
    "        if format_:\n",
    "            artist = format_string(artist)\n",
    "            \n",
    "        query = {'q':title + ' ' + artist}\n",
    "        response = requests.get(search_url,data=query,headers=headers)\n",
    "        search_hits = response.json()['response']['hits']\n",
    "        \n",
    "        song_path = search_path(artist,title,search_hits,format_)\n",
    "            \n",
    "        return response,song_path\n",
    "    \n",
    "    response,song_path = get_path(artist,title,headers)\n",
    "    if song_path == '':\n",
    "#         print(f'No search result found for {artist},{title}')\n",
    "        requires_formatting = requires_formatting(artist)\n",
    "#         print(f'{artist} requires formatting: {requires_formatting}')\n",
    "        response,song_path = get_path(artist,title,headers,format_=True)\n",
    "    \n",
    "    return song_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_lyrics(path):\n",
    "    genius_web = 'https://genius.com/'\n",
    "    page = requests.get(genius_web+path).content\n",
    "    soup = bs(page,'html.parser')\n",
    "    lyrics_content = soup.find('div',class_='lyrics').findAll('a')\n",
    "    lyrics = []\n",
    "    \n",
    "    for i in range(len(lyrics_content)):\n",
    "        lyrics.append(lyrics_content[i].get_text())\n",
    "    \n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_path = fetch_song_info('Radiohead','true love waits',token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = scrape_lyrics(song_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’ll drown my beliefs\n",
      "To have your babies\n",
      "I’ll dress like your niece\n",
      "And wash your swollen feet\n",
      "Just don’t leave\n",
      "Don’t leave\n",
      "I’m not living\n",
      "I’m just killing time\n",
      "Your tiny hands\n",
      "Your crazy kitten smile\n",
      "Just don’t leave\n",
      "Don’t leave\n",
      "And true love waits\n",
      "In haunted attics\n",
      "And true love lives\n",
      "On lollipops and crisps\n",
      "Just don’t leave\n",
      "Don’t leave\n"
     ]
    }
   ],
   "source": [
    "for verse in lyrics:\n",
    "    print(verse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Billboard Hot 100 Songs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_100(date):\n",
    "    \"\"\"Function to scrape the Billboard Hot 100 tracks\n",
    "       \n",
    "       Parameters:\n",
    "       -----------\n",
    "       date(string): date to fetch data for. should be of YYYY-MM-DD format\n",
    "       \n",
    "       Returns:\n",
    "       --------\n",
    "       pandas dataframe containing the artist names and track titles\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://www.billboard.com/charts/hot-100/' + date\n",
    "    response = requests.get(url)\n",
    "    hot_soup = bs(response.content,'html.parser')\n",
    "    \n",
    "    no1_artist = hot_soup.find('div',class_=\"chart-number-one__artist\").text.split('\\n')[2]\n",
    "    no1_title = hot_soup.find('div',class_=\"chart-number-one__title\").text\n",
    "    \n",
    "    artists = [item[\"data-artist\"] for item in hot_soup.find_all('div',class_=\"chart-list-item\") if \"data-artist\" in item.attrs]\n",
    "    titles = [item[\"data-title\"] for item in hot_soup.find_all('div',class_=\"chart-list-item\") if \"data-title\" in item.attrs]\n",
    "    \n",
    "    artists = [no1_artist] + artists\n",
    "    titles = [no1_title] + titles\n",
    "    \n",
    "    hot100 = pd.DataFrame({'Artist':artists,'Title':titles})\n",
    "    \n",
    "    return hot100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot100 = get_hot_100('2018-08-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,song in hot100.iterrows():\n",
    "    \n",
    "    path = fetch_song_info(song['Artist'],song['Title'],token)\n",
    "    if path !='':\n",
    "        l = scrape_lyrics(path)\n",
    "        lyrics.append(l)\n",
    "    else:\n",
    "        not_found.append((song['Artist'],song['Title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Carters', 'Apes**t'),\n",
       " ('Casper Magico, Nio Garcia, Darell, Nicky Jam, Ozuna & Bad Bunny',\n",
       "  'Te Bote'),\n",
       " ('Quavo', 'W O R K I N  M E'),\n",
       " ('Travis Scott', 'R.I.P Screw'),\n",
       " ('Luke Combs', 'She Got The Best Of Me ')]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot Songs within a date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user inputs starting date and ending date as strings\n",
    "start_input = '2017-08-25'\n",
    "end_input = '2018-08-25'\n",
    "\n",
    "#convert to datetime objects\n",
    "start_date = dt.datetime.strptime(start_input,'%Y-%m-%d').date()\n",
    "end_date = dt.datetime.strptime(end_input,'%Y-%m-%d').date()\n",
    "#create time delta for a week\n",
    "delta = dt.timedelta(days=7)\n",
    "weeks = round((end_date - start_date)/delta)\n",
    "\n",
    "dates = [str(start_date+x*delta) for x in range(weeks+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_100_range(start,end):\n",
    "    \"\"\"Function to scrape the Billboard Hot 100 tracks over a date range\n",
    "       \n",
    "       Parameters:\n",
    "       -----------\n",
    "       date(string): date to fetch data for. should be of YYYY-MM-DD format\n",
    "       \n",
    "       Returns:\n",
    "       --------\n",
    "       pandas dataframe containing the artist names and track titles\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    #convert to datetime objects\n",
    "    start_date = dt.datetime.strptime(start,'%Y-%m-%d').date()\n",
    "    end_date = dt.datetime.strptime(end,'%Y-%m-%d').date()\n",
    "    #create time delta for a week\n",
    "    delta = dt.timedelta(days=7)\n",
    "    weeks = round((end_date - start_date)/delta)\n",
    "\n",
    "    dates = [str(start_date+x*delta) for x in range(weeks)]\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for date in dates:\n",
    "#         print(date)\n",
    "        url = 'https://www.billboard.com/charts/hot-100/' + date\n",
    "        response = requests.get(url)\n",
    "        hot_soup = bs(response.content,'html.parser')\n",
    "\n",
    "        no1_artist = hot_soup.find('div',class_=\"chart-number-one__artist\").text.split('\\n')[2]\n",
    "        no1_title = hot_soup.find('div',class_=\"chart-number-one__title\").text\n",
    "\n",
    "        artists = [item[\"data-artist\"] for item in hot_soup.find_all('div',class_=\"chart-list-item\") if \"data-artist\" in item.attrs]\n",
    "        titles = [item[\"data-title\"] for item in hot_soup.find_all('div',class_=\"chart-list-item\") if \"data-title\" in item.attrs]\n",
    "\n",
    "        artists = [no1_artist] + artists\n",
    "        titles = [no1_title] + titles\n",
    "        \n",
    "        for a,t in zip(artists,titles):\n",
    "            if [a,t] not in data:\n",
    "                data.append([a,t])\n",
    "#         print(f'Data added for the week of date: {date}')\n",
    "        \n",
    "    hot100 = pd.DataFrame(data,columns=['Artist','Title'])\n",
    "    \n",
    "    return hot100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot100_2018 = get_hot_100_range('2018-01-01','2018-09-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Post Malone Featuring 21 Savage</td>\n",
       "      <td>Rockstar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Camila Cabello Featuring Young Thug</td>\n",
       "      <td>Havana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lil Pump</td>\n",
       "      <td>Gucci Gang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G-Eazy Featuring A$AP Rocky &amp; Cardi B</td>\n",
       "      <td>No Limit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Artist       Title\n",
       "0                             Ed Sheeran     Perfect\n",
       "1        Post Malone Featuring 21 Savage    Rockstar\n",
       "2    Camila Cabello Featuring Young Thug      Havana\n",
       "3                               Lil Pump  Gucci Gang\n",
       "4  G-Eazy Featuring A$AP Rocky & Cardi B    No Limit"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot100_2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drake           23\n",
       "Travis Scott    17\n",
       "Post Malone     14\n",
       "J. Cole         11\n",
       "XXXTENTACION     9\n",
       "Name: Artist, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot100_2018['Artist'].value_counts().head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
